%!TEX root = ./main.tex
\section{Experiments and Results}\label{4_experiment}
We have run a number of experiments based on several common real world scenarios, and we compared our approach with other popular methods through the experiments.
% \begin{itemize}
%     \item How effective MERec performs in $Pure$ $Cold$ and $Sparse dataset$.
%     \item How dose MERec compare with other state-of-the-art methods
% \end{itemize}
\subsection{Dataset and experiment setup}
Our experiments is based on HetRec 2011 \cite{CantadorRecSys2011} data set. To construct the HIN, We use movies which have at least 10 distinctive user views. We also limit top 3 actors/actresses to be associated. We use tags information which is shared by more than 1 movies. In the end, we concluded 6 different types of $node$ which can be used in HI: $Users$, $Movies$, $Tags$, $Actors$, $Directors$, $Genres$.
Additionally, 5 relationships are defined as edges, which are $Movie-Users$, $Movie-Tags$, $Movie-Actors$, $Movie-Directors$, and $Movie-Genres$.

For the simplicity of the experiment, we weigh all of our meta-path equally, as it is sufficient in illustrating the effectiveness of MERec. On the other hand, we do acknowledge that, those hyper-parameters can be further tuned to improve the result to tailor different problem domains. 

For pure cold-start problem, we split our data set based on time. We use movies prior 2008 as training data set (6724 movies), and 2008~2011 as testing data set (193 movies). The choice of meta-path in this experiment are: $Movie-Tags-Movie$, $Movie-Actors-Movie$, $Movie-Directors-Movie$, and $Movie-Genres-Movie$. In this problem setting, we compare our result with common One-Hot encoding approach for categorical data in content based recommendation approach.

For data sparsity problem, we split data in two sparse ratios to evaluate the effectiveness of MERec performance. we also compares it with CF+BPR, which is one of the most popular and effective algorithms. For sparse data scenarios, the data density set to be \text{1.1\%}, while in non-sparse experiment settings, the density is set at \text{2.3\%}.

\subsection{Experiment results}
In pure cold start case, as shown in Table \ref{tbl1}, the MERec is far superior comparing to one hot encoding when handling complex categorical.

\begin{table}
    \tbl{Pure cold start comparison results}
    {\begin{tabular}{@{}ccccc@{}}\toprule
    Models & Precision@5 & Recall@5 & Precision@10 & Recall@10 \\
    \colrule
    One-Hot\hphantom{00} & \hphantom{0} 0.1229 & \hphantom{0} 0.0146 & 0.1481 & 0.0334 \\
    MERec\hphantom{00} & \hphantom{0} \textbf{0.3037} & \hphantom{0} \textbf{0.0402} & \textbf{0.2711} & \textbf{0.0665} \\
    
    \botrule
    \end{tabular}
    }\label{tbl1}
    % \begin{tabnote}
    % $^{\text a}$ M.E. stands for meta-path embedding\\
    % \end{tabnote}
    \end{table}
As shown in the result, when dealing with complex categorical data. EMRec had shown a significant edge comparing with one-hot encoding approach, with near doubling both precision and recall in pure cold start problem settings.

We run experiment on both sparse data split as well as non-sparse data split. we see the comparison as below in table \ref{tbl2}: 
\begin{table}
    \tbl{Sparse data comparison results}
    {\begin{tabular}{@{}cccccc@{}}\toprule
    Data sparsity &Models & Precision@5 & Recall@5 & Precision@10 & Recall@10 \\
    \colrule
    1.1\%&MF\hphantom{00} & \hphantom{0} 0.5498 & 0.0126 & 0.5548 & 0.0265 \\
    &MERec\hphantom{00} & \hphantom{0} \textbf{0.6194} & \textbf{0.0163} & \textbf{0.6035} & \textbf{0.0308} \\
    \colrule
    2.3\%&MF\hphantom{00} & 0.5566 & 0.0175 & 0.5419 & 0.0336 \\
    &MERec\hphantom{00} & \hphantom{0} \textbf{0.5858} & \textbf{0.0195} & \textbf{0.5575} & \textbf{0.0355} \\
    \botrule
    \end{tabular}
    }
    \label{tbl2}
\end{table}
In sparse data split, we can see in average a near 20\% performance boost comparing to Traditional Matrix Factorization based approach. 
While in non-sparse case, we can still see some minor enhancement across precision and recall.

Through above 3 experiments, EMRec exhibits a stable superior performance in various data quality scenarios.

