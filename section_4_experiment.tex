\section{EXPERIMENTS AND RESULTS}\label{4_experiment}
We have run a number of experiments based on several common real world scenarios, and we compared our approach with other popular methods through the experimentation:
\begin{itemize}
    \item How effective MERec performs in $Pure$ $Cold$ and $Sparse dataset$.
    \item How dose MERec compare with other state-of-the-art methods
\end{itemize}

\subsection{Data Set}
Our experiments is based on HetRec 2011 \cite{CantadorRecSys2011} data set, which is a extension of MovieLens10M data enriched with content data collected from IMDb and Rotten Tomatoes.
First, we prune the data. For movies, we only picks the movie with at least 10 distinctive user views. we also limit top 3 actors/actresses to be associated. In terms of Tags, we use tags information which is shared by more than 1 movies. In the end, we concluded 6 different types of $node$ which can be used in heterogeneous information graph, shown as following: $Users$, $Movies$, $Tags$, $Actors$, $Directors$, $Genres$.
Additionally, following 5 relationships is defined as edges, which are $Movie-Users$, $Movie-Tags$, $Movie-Actors$, $Movie-Directors$, and $Movie-Genres$:

For the simplicity of the experiment, we weigh all of our meta-path equally, as it is sufficient in illustrating the effectiveness of MERec. On the other hand, we do acknowledge that, those hyper-parameters can be further tuned to improve the result to tailor different problem domains. 


\subsection{Experiment setup}
We split our data set based on time, and use it to demonstrate MERec's approach in dealing pure cold start problem.
we use movies prior 2008 as training data set (6724 movies), and 2008~2011 as testing data set (193 movies). 
The choice of meta-path in this experiment are: $Movie-Tags-Movie$, $Movie-Actors-Movie$, $Movie-Directors-Movie$, and $Movie-Genres-Movie$. 
Finally, we compare our result with common One-Hot encoding approach for categorical data in content based recommendation approach.

For data sparsity problem, we split data into 2 different density distribution to evaluate the effectiveness of MERec performance in both sparse and dense dataset. we also compares it with CF+BPR, which is being one of the most popular and effective algorithms. For sparse data scenarios, the data density set to be \text{1.1\%}, while in non-sparse experiment settings, the density is set at \text{2.3\%}


\subsection{Results comparison}
In pure cold start case, see Table \ref{tbl1}, meta-path based embedding approach is far superior comparing to one hot encoding when handling complex categorical.

\begin{table}
    \tbl{Pure cold start comparision results}
    {\begin{tabular}{@{}ccccc@{}}\toprule
    Models & Precision@5 & Recall@5 & Precision@10 & Recall@10 \\
    \colrule
    One-Hot\hphantom{00} & \hphantom{0} 0.1229 & \hphantom{0} 0.0146 & 0.1481 & 0.0334 \\
    M.E.\hphantom{00} & \hphantom{0} \textbf{0.3037} & \hphantom{0} \textbf{0.0402} & \textbf{0.2711} & \textbf{0.0665} \\
    
    \botrule
    \end{tabular}
    }
    \begin{tabnote}
    $^{\text a}$ M.E. stands for meta-path embedding\\
    \end{tabnote}
    \label{tbl1}
    \end{table}



In sparse data cases, we can see in average near 10\% performance boost in precision, as shown in Table \ref{tbl2}:

\begin{table}
    \tbl{Sparse data comparison results}
    {\begin{tabular}{@{}ccccc@{}}\toprule
    Models & Precision@5 & Recall@5 & Precision@10 & Recall@10 \\
    \colrule
    C.F.+BPR\hphantom{00} & \hphantom{0} 0.5498 & 0.0126 & 0.5548 & 0.0265 \\
    MERec\hphantom{00} & \hphantom{0} \textbf{0.6194} & \textbf{0.0163} & \textbf{0.6035} & \textbf{0.0308} \\
    
    \botrule
    \end{tabular}
    }
    \label{tbl2}
\end{table}


While in non-sparse cases, we can still see equivalent or minor enhancement across precision and recall, as in Table \ref{tbl3}:
    
\begin{table}
    \tbl{Sparse data comparison results}
    {\begin{tabular}{@{}ccccc@{}}\toprule
    Models & Precision@5 & Recall@5 & Precision@10 & Recall@10 \\
    \colrule
    C.F.+BPR\hphantom{00} & 0.5566 & 0.0175 & 0.5419 & 0.0336 \\
    MERec\hphantom{00} & \hphantom{0} \textbf{0.5858} & \textbf{0.0195} & \textbf{0.5575} & \textbf{0.0355} \\
    
    \botrule
    \end{tabular}
    }
    \label{tbl3}
\end{table}
    








